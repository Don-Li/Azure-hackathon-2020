---
title: 'Deriving variables: Distance'
author: "Don Li"
date: "05/06/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library( data.table )
library( caret )
library( mgcv )
# source( "G:/azure_hackathon/data/Don/utility.R" )
```

# Data and stuff

Load data. This contains test set, training set, and controls for 7-fold CV.
```{r}
load( "G:/azure_hackathon/datasets2/model_subset/testing_subset.RData" )
```

# Note
I forgot to use the historical data here. But, I looked at it for a bit and it doesn't make a lot of difference

# What are we doing here?

In this document, we want to consider predicting path distance. You will note that in the model inputs, path distance is not a given input:

* latitude_origin
* longitude_origin
* latitude_destination
* longitude_destination
* hour_of_day
* day_of_week

Although we can compute the distance as the crow flies (CF), we will also need the path distance. In our ETA model, we will use path distance, but we will treat it as a missing value. Therefore, we will need some model-based imputation to get some path distance information.

Brief note: The landmarks variables made the models really bad. Probably because the factors force complete pooling of observations and fragments the data too much.

A view of the variables before we start.

```{r}
head( training_set )
```

# Baseline

For our baselines, we will use the Azure and OSRM distances.

```{r}
azure_baseline = sqrt( mean( (test_set$path_dist - test_set$azure_dist)^2 ) )
azure_baseline

osrm_baseline = sqrt( mean( (test_set$path_dist - test_set$OSRM_dist)^2 ) )
osrm_baseline
```

```{r eval = FALSE}
vars_to_rm = c("trj_id", "timediff", "path_dist2", "sampling_rate",
    "log_sampling_rate_var", "mean_speed", "log_var_speed" )
test_set_all = copy(test_set)
training_set = copy(training_set)
test_set[ , eval(vars_to_rm) := NULL ]
training_set[ , eval(vars_to_rm) := NULL ]
```


# Linear regression

```{r fig.height = 10, fig.width = 10}
xvars = setdiff( names(training_set), "path_dist" )
par( mfrow = c(3, 4) )
col = rgb( 0, 0, 0, 0.25 )
for ( x in xvars ){
    plot( training_set[[x]], training_set$path_dist,
        main = x, col = col, pch = 16 )
    lines( smooth.spline( training_set[[x]], training_set$path_dist ),
        col = "red")
}

```

Linear regression. All second-order interactions, but some of the weird ones removed. Some quadratics for the start/end locations.

```{r eval=FALSE}
model_formula_lm = path_dist ~ .*. +
    I(start_x^2) + I(start_y^2) + I(end_x^2) +  I(end_y^2) +
    I(hour^2) + I(hour^3)  -
    start_x:end_x - start_x:start_y - start_x:end_y -
    start_y:end_x - start_y:start_y - start_y:end_y -
    trip_start*. - trip_end*.

lm_ = train( form = model_formula_lm,
    data = training_set,
    metric = "RMSE", method = "lm", trControl = train_control)

lm_results = data.table( lm_$results )
lm_pred = data.table( lm_$pred )
setorder( lm_pred, rowIndex )

save( lm_, lm_results, lm_pred, 
    file = "G:/azure_hackathon/datasets2/expo/lm.RData" )
```


```{r}
load( "G:/azure_hackathon/datasets2/expo/lm.RData" )
lm_results
```

CV error is `r round(lm_results$RMSE,3)`. Better than out baselines.

# Elastic net

Elastic net.

```{r eval = FALSE}

n_enet = 50
enet_tunegrid = data.frame(
    lambda = rexp( n_enet, 1/0.0001 ),
    fraction = runif( n_enet, 0.9, 1 )
)
enet_ = train( form = model_formula_lm, data = training_set,
    metric = "RMSE", method = "enet", trControl = train_control,
    tuneGrid = enet_tunegrid, standardize = TRUE
    )

enet_results = data.table( enet_$results )
enet_pred = data.table( enet_$pred )
setorder( enet_pred, rowIndex )

save( enet_, enet_results, enet_pred, 
    file = "G:/azure_hackathon/datasets2/expo/enet.RData" )
```

RMSE is around the same as the linear model.

```{r fig.height=6, fig.width=5}
load( "G:/azure_hackathon/datasets2/expo/enet.RData" )
enet_results[ which.min(RMSE) ]
par( mfrow = c(2, 1 ) )
enet_results[ , {
    plot( fraction, RMSE, type = "o" )
    nu_order = order(lambda)
    plot( lambda[nu_order], RMSE[nu_order], type = "o" )
} ]
```

# Partial least squares

PLS.

```{r eval = FALSE}
full_X = ncol( model.matrix( model_formula_lm, training_set) )
pls_tunegrid = data.frame( ncomp = 1:full_X )
pls_ = train( form = model_formula_lm, data = training_set,
    metric = "RMSE", method = "pls", trControl = train_control,
    tuneGrid = pls_tunegrid
    )

pls_results = data.table( pls_$results )
pls_pred = data.table( pls_$pred )
setorder( pls_pred, rowIndex )

save( pls_, pls_results, pls_pred, 
    file = "G:/azure_hackathon/datasets2/expo/pls.RData" )
```


```{r fig.height=4, fig.width=4}
load( "G:/azure_hackathon/datasets2/expo/pls.RData" )
pls_results[ which.min(RMSE) ]
pls_results[ RMSE < 2.3, {
    plot( ncomp, RMSE, type = "o" )
} ]
```

# Principal components regression

PCR.

```{r eval = FALSE}
full_X = ncol( model.matrix( model_formula_lm, training_set) )
pcr_tunegrid = data.frame( ncomp = 1:full_X )
pcr_ = train( form = model_formula_lm, data = training_set,
    metric = "RMSE", method = "pcr", trControl = train_control,
    tuneGrid = pcr_tunegrid
    )

pcr_results = data.table( pcr_$results )
pcr_pred = data.table( pcr_$pred )
setorder( pcr_pred, rowIndex )

save( pcr_, pcr_results, pcr_pred, 
    file = "G:/azure_hackathon/datasets2/expo/pcr.RData" )
```

```{r}
load( "G:/azure_hackathon/datasets2/expo/pcr.RData" )
pcr_results[ which.min(RMSE) ]
pcr_results[ RMSE < 2.3, {
    plot( ncomp, RMSE, type = "o" )
} ]
```

# KNN

KNN.

```{r eval = FALSE}
k_grid = data.frame( k = 5:30 )

knn_ = train( form = model_formula_lm, data = training_set,
    metric = "RMSE", method = "knn", trControl = train_control,
    tuneGrid = k_grid
    )

knn_results = data.table( knn_$results )
knn_pred = data.table( knn_$pred )
setorder( knn_pred, rowIndex )

save( knn_, knn_results, knn_pred,
    file = "G:/azure_hackathon/datasets2/expo/knn.RData" )
```

```{r}
load( "G:/azure_hackathon/datasets2/expo/knn.RData" )
knn_results[ which.min(RMSE) ]
knn_results[ , plot( k, RMSE, type = "o" ) ]
```

# CART

Use an Exponential distribution for our random search.

```{r eval = FALSE}
cp_grid = data.frame( cp = rexp( 100, 1/0.001 ) )

rpart_ = train( path_dist ~ ., 
    data = training_set,
    metric = "RMSE", method = "rpart", trControl = train_control,
    tuneGrid = cp_grid
    )

rpart_results = data.table( rpart_$results )
rpart_pred = data.table( rpart_$pred )
setorder( rpart_pred, rowIndex )

save( rpart_, rpart_results, rpart_pred,
    file = "G:/azure_hackathon/datasets2/expo/rpart.RData" )
```

```{r}
load( "G:/azure_hackathon/datasets2/expo/rpart.RData" )
rpart_results[ which.min(RMSE) ]
plot( rpart_results$cp, rpart_results$RMSE, type = "l" )
```

# GAM splines
Generalised additive model using splines

```{r eval = FALSE}
gam_grid = expand.grid(
    select = F,
    method = c( "GACV.Cp", "REML", "ML" )
)

gam_ = train( 
    path_dist ~ . +
            I(start_x^2) + I(start_y^2) + I(end_x^2) +  I(end_y^2) +
    I(hour^2) + I(hour^3)
    , data = training_set,
    metric = "RMSE", method = "gam", trControl = train_control,
    tuneGrid = gam_grid
)

gam_results = data.table( gam_$results )
gam_pred = data.table( gam_$pred )
setorder( gam_pred, rowIndex )

save( gam_, gam_results, gam_pred,
    file = "G:/azure_hackathon/datasets2/expo/gam_spline.RData" )
```

```{r}
load( "G:/azure_hackathon/datasets2/expo/gam_spline.RData" )
gam_results[ which.min(RMSE) ]
```

# Stacking

```{r eval = FALSE}
training_OOF = data.table(
    lm = lm_pred$pred,
    enet = enet_pred$pred,
    pls = pls_pred$pred,
    pcr = pcr_pred$pred,
    knn = knn_pred$pred, 
    rpart = rpart_pred$pred,
    gam = gam_pred$pred,
    path_dist = training_set$path_dist
    # training_set
)

test_OOF = data.table(
    lm = predict( lm_, test_set ),
    enet = predict( enet_, test_set ),
    pls = predict( pls_, test_set ),
    pcr = predict( pcr_, test_set ),
    knn = predict( knn_, test_set ),
    rpart = predict( rpart_, test_set ),
    gam = predict( gam_, test_set ),
    path_dist = test_set$path_dist
    # test_set
)

stacking_model_formula = path_dist ~ .

stacked_tunegrid = data.frame( ncomp = 1:(ncol(training_OOF)-1) )
stacking = train( stacking_model_formula, data = training_OOF,
    metric = "RMSE", method = "pls", trControl = train_control,
    tuneGrid = stacked_tunegrid
    )

stacking_results = data.table( stacking$results )
stack_pred_OOF = predict( stacking, test_OOF )

save( stacking_results, stack_pred_OOF, test_OOF,
    file = "G:/azure_hackathon/datasets2/expo/stack.RData" )
```

```{r}
load( "G:/azure_hackathon/datasets2/expo/stack.RData" )


stacked_rmse = sqrt( mean( ( stack_pred_OOF - test_OOF$path_dist )^2 ) )

all_rmse = rbind(
    as.matrix(sqrt( colMeans( ( test_OOF - test_OOF$path_dist )^2 ) )),
    stack = stacked_rmse
)

(all_rmse[ order(all_rmse), ][-1])
```

Stacking does a pretty good job. But GAMs are pretty good, but I think this is just a strange sample. I tried with other samples in the dataset and the stack was better for them.

# Conclusion

Stack a bunch of models for imputing distance.

Recall that I have a bad distance where I swap the longitude and the latitudes in the calculation. I don't know why, but it ends up being quite good in the model. I suspect it is like a PCA kind of effect.

To impute the proper Haversine, I will impute the terrible Haversine first:

* Impute the Haversine2 distance (longs and lats swapped).
* Use the Haversine2 with the other variables to impute the Haversine (longs and lats right way).






























