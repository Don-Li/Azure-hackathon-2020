---
title: "basic_regression"
author: "Don Li"
date: "02/06/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library( data.table )
```

Our objective is to predict the estimated time of arrival for a journey. We will start with the most basic model, linear regression. Then we will build it up from there.

# Workflow stuff

Read the data in with Python. I will use R for prototyping because we only have two weeks and I don't have time to get good at the snake language.

```{python eval=FALSE}
import numpy as np
import pandas as pd
import pickle
import os
from datetime import datetime
import pyarrow.parquet as pq
import matplotlib.pyplot as plt

pd.set_option( "display.max_columns", None )

filename = "part-00000-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet"
dataset = pq.read_table( filename ).to_pandas()
```

When this Py chunk gets evaluated, it returns an R dataframe. The result of the document will be working on that dataframe.

# Variable transformations

The `pingtimestamp` has a lot of information. I think the day of the month (`monthday`), day of the year (`yearday`), day of the week (`weekday`), the month (`month`), hour (`hour`), and minute `min`, will be useful. Of couse, we also want the actual date so we can compute differences in time.

```{r eval = FALSE}
dataset = data.table( dataset )
dataset = dataset[ order( trj_id, pingtimestamp ) ]

dataset[ , c("monthday", "yearday", "weekday", "date", "month",
    "hour", "min") := {
    date_ = .POSIXct(pingtimestamp)
    monthday = as.numeric( format( date_, "%d" ) )
    
    yearday = format( date_, "%W" )

    weekday = format( date_, "%a" )
    weekday = factor( weekday, 
        levels = c("Sun", "Mon", "Tue", "Wed",
            "Thu", "Fri", "Sat") )
    
    month_F = format( date_ , "%b" )
    
    month_F = factor( month_F, ordered = T )
    
    hour = as.numeric( format( date_, "%H" ) )

    min = as.numeric( format( date_, "%M" ) )
    
    list( day = monthday, yearday = yearday,
        weekday = weekday,
        date_ = date_,
        month = month_F,
        hour = hour, min = min )
    } ]
```

A function to get the time difference in seconds.
```{r}
difftime_mins = function( time1, time2 ){
    x = difftime( time1, time2, units = "secs" )
    as.numeric(x)
}
```

# First model

Our most basic model is regressing the estimated time of arrival based on trip-level information. So, this is not a moment-by-moment solution at the moment. This is just to see what is or could be important, and it also serves as a base case.

We will also add additional variables, such as the mean speed over the trip (`speed_avg`) and also the variance fo the speed (`speed_var`). We also use the Euclidean distance (`dist_`).

```{r eval = FALSE}
summary_data = dataset[ , {
    indices = c(1,.N)
    
    lat_diff = diff( rawlat[indices] )
    lng_diff = diff( rawlng[indices] )
    dist_ = sqrt( lat_diff^2 + lng_diff^2 )
    
    timediff = difftime_mins( date[.N], date[1] ) 
    
    speed_avg = mean(speed)
    speed_var = var(speed)
    
    monthday_ = monthday[1]
    weekday_ = weekday[1]
    yearday_ = yearday[1]
    hour_ = hour[1]
    min_ = min[1]
    month_ = month[1]
    
    list( dist_ = dist_, timediff = timediff, speed_avg = speed_avg,
        speed_var = speed_var, weekday_ = weekday_,
        hour_ = hour_, min_ = min_, month_ = month_)
}, by = "trj_id" ]
save( dataset, summary_data, file = "Don/regression1.RData" )
```

# Exploratory analysis

```{r}
load( "Don/regression1.RData" )
set.seed(1)
n = nrow( summary_data )
training_set_id = sample( 1:n, n * 0.75 )
training_set = summary_data[ training_set_id ]
test_set = summary_data[ -training_set_id ]
```

In the next figure, we have the empirical distributions of each of our covariates.

```{r fig.height=16, fig.width=16}
par( mfrow = c(3,2), cex = 1.5 )
varlist = setdiff( names(training_set), c("timediff","trj_id", "month_") )
for ( v in varlist ){
    data_ = training_set[[v]]
    if ( is.numeric( data_ ) ){
        breaks = 100
        if ( v == "hour_" ) breaks = 0:24 - 0.5
        if ( v == "min_" ) breaks = 0:60 - 0.5
        hist( data_, main = v, breaks = breaks )
    } else{
        plot(data_, main = v)
    }
}
```

We could explore different distance measures. The world is not flat (possible?), so maybe the Euclidean distance is not great. Routes are also not straight lines, so maybe an L1 distance would be nice? Not sure. I think the best would be to find how long the road distance is between two points.

Could try logarithmic transformations for speed variance.

We see that there are fewer trips around 5am. Could be useful if we want to do a generalised least-squares solution. We could down-weight hours that are less frequent.

The next figure is the empirical distribution of the arrival times. There are some extreme outliers for some reason.

```{r fig.height=5, fig.width=16}
par( mfrow = c(1,2), cex = 1 )
hist( training_set$timediff, breaks = 1000, main = "Arrival time",
    xlab = "Arrival time (s)")
hist( training_set[timediff < quantile(timediff, 0.99)]$timediff, 
    breaks = 1000, main = "Arrival time (ex longest 1%)",
    xlab = "Arrival time (s)")
```

Next figure is a bivariate analysis. Again, the extreme outlier(s) really mess up the visualisation.

```{r fig.height=16, fig.width=16}
par( mfrow = c(3,2), cex = 1.5 )
for ( v in varlist ){
    plot( training_set[[v]], training_set$timediff, 
        pch = 16, cex = 0.5,
        xlab = v, ylab = "Time difference")
    try({
    lines( smooth.spline( training_set[[v]], 
        training_set$timediff ), col = "red" )
    })
}
```

```{r fig.height=16, fig.width=16}
par( mfrow = c(3,2), cex = 1.5 )
for ( v in varlist ){
    training_set[ timediff < quantile(timediff, 0.99), {
        var_ = get(v)
        plot( var_, timediff, 
            pch = 16, cex = 0.5,
            xlab = v, ylab = "Time difference")
        try({
            lines( smooth.spline( var_, 
                timediff ), col = "red" )
        })
        NULL
    } ]
}
```

# Testing the model
Remove month because we only have one month in this subset. We have all the pairwise interactions.
```{r}
training_set[ , month_ := NULL ]
training_set[ , trj_id := NULL ]
lm_ = lm( timediff ~ .*., training_set )
anova( lm_ )
```

The ANOVA table suggests that the minute that the trip starts is not relevant.

Just with a simple model, our R^2 is about 50%, which is pretty good for a large dataset and the little work that I've done so far.
```{r}
summary(lm_)
```

Our RMSE is about 220 seconds. So, about 3mins, 40 seconds on average.
```{r}
yhat = predict( lm_, test_set )
rmse = sqrt( mean( (yhat - test_set$timediff)^2 ) )
rmse
```

```{r fig.height=4, fig.width=5}
par( cex = 1.5 )
hist( abs(yhat - test_set$timediff), main = "Abs errors", 
    xlab = "Absolute prediction errors (s)",
    breaks = 1000 )
```

```{r fig.height = 5, fig.width = 5}
par( cex = 1.5 )
total_range = range( c( yhat, test_set$timediff ) )
plot( yhat, test_set$timediff, pch = 16, cex = 0.5,
    main = "Observed vs predicted",
    xlab = "Predicted ETA (s)",
    ylab = "Observed arrival (s)", asp = 1,
    xlim = total_range, ylim = total_range
    )
abline( 0, 1 )
```

Taking the distribution of errors and the observed vs preidction plots together, it suggests that our basic model fails mostly because of under-prediction. There are a couple of very long journeys over short distances (e.g., fat loop around the city). Not sure how to handle this with the basic model.